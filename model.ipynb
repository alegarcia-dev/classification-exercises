{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c19598-ef0c-4f29-8886-eeb7d26f639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from acquire import *\n",
    "from prepare import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85da0049-7b04-47cf-88b5-5849cf11ca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 11), (214, 11), (179, 11))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = get_titanic_data()\n",
    "titanic = prep_titanic_data(titanic)\n",
    "train, validate, test = split_data(titanic, 'survived')\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db29e56c-9ca9-48e0-a503-9bdcd1fa583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['pclass', 'sex_male', 'alone']\n",
    "\n",
    "X_train = train[columns]\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate[columns]\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test[columns]\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1711ab2c-cbf7-4427-8fe7-86f69b9126c0",
   "metadata": {},
   "source": [
    "# Decision Tree Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308768e-8181-4eea-aa44-b1836840c1e5",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17755f8d-b5f6-40c6-8be0-9d646da82a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616466\n",
       "1    0.383534\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043debc-1693-4908-ad90-07b74271b5a9",
   "metadata": {},
   "source": [
    "Our baseline model would be predicting the most common target value, which is did not survive. Given a baseline model that always predicts did not survive the accuracy of this model would be ~62%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d1c26-bc2f-43de-b0cd-cd232265ec6d",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647669e4-de69-4b5b-9195-8350b5504c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DecisionTreeClassifier(max_depth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0abea884-ad13-4b94-92a0-df1b6c275a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8ced740-434e-4c27-ac78-ff05f9f313e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model1.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb9017-0873-4a12-82c3-dc4eaadd6335",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n",
    "Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "641927fb-4a03-434c-b5e3-282c5746f26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7831325301204819"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d85e8ff6-193d-4356-895d-9a9d855cee42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Did Not Survive</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Did Not Survive</th>\n",
       "      <td>303</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Survived</th>\n",
       "      <td>104</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Predicted Did Not Survive  Predicted Survived\n",
       "Actual Did Not Survive                        303                   4\n",
       "Actual Survived                               104                  87"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_labels = ['Actual Did Not Survive', 'Actual Survived']\n",
    "column_labels = ['Predicted Did Not Survive', 'Predicted Survived']\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred, labels = [0, 1]), index = index_labels, columns = column_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04d3eeee-2ef0-4085-bfc4-4872f51c056f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.85       307\n",
      "           1       0.96      0.46      0.62       191\n",
      "\n",
      "    accuracy                           0.78       498\n",
      "   macro avg       0.85      0.72      0.73       498\n",
      "weighted avg       0.83      0.78      0.76       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5de4a-2728-44aa-9b6d-74ac24e974d7",
   "metadata": {},
   "source": [
    "## 4\n",
    "\n",
    "Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd7bcb-feb6-4f42-aa72-4f9b5aa87629",
   "metadata": {},
   "source": [
    "> Accuracy:            0.78\n",
    "<br>\n",
    "> True Positive Rate:  0.17\n",
    "<br>\n",
    "> False Positive Rate: 0.008\n",
    "<br>\n",
    "> True Negative Rate:  0.61\n",
    "<br>\n",
    "> False Negative rate: 0.21\n",
    "<br>\n",
    "> Precision:           0.96, 0.74\n",
    "<br>\n",
    "> Recall:              0.46, 0.99\n",
    "<br>\n",
    "> f1-score:            0.62, 0.85\n",
    "<br>\n",
    "> Support:             498"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5435ce-1596-47e6-a839-3920b3c85808",
   "metadata": {},
   "source": [
    "## 5\n",
    "\n",
    "Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "779112c5-6d2d-44f2-8022-1553e4c8ec72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = DecisionTreeClassifier(max_depth = 4)\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred = model2.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca5046f-e3b4-4cd3-8040-cbbf50931961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7951807228915663"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36075002-e09c-4d30-9f9f-f369f609099e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Did Not Survive</th>\n",
       "      <th>Predicted Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Did Not Survive</th>\n",
       "      <td>286</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Survived</th>\n",
       "      <td>81</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Predicted Did Not Survive  Predicted Survived\n",
       "Actual Did Not Survive                        286                  21\n",
       "Actual Survived                                81                 110"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_train, y_pred, labels = [0, 1]), index = index_labels, columns = column_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f094f5b-9d73-446a-a525-fecb4b1848ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85       307\n",
      "           1       0.84      0.58      0.68       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.81      0.75      0.77       498\n",
      "weighted avg       0.80      0.80      0.79       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcdd38-6fac-4e4c-b7c4-a12ae56d2813",
   "metadata": {},
   "source": [
    "## 6\n",
    "\n",
    "Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51b080-2b3f-4c55-973c-392f7a84a8ae",
   "metadata": {},
   "source": [
    "> In terms of accuracy model 2 performed better, but only slightly better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376be61d-c7a3-4eda-8f94-5482b48250ac",
   "metadata": {},
   "source": [
    "## 7\n",
    "\n",
    "Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df493b36-a433-4ff4-a838-bb213ac548b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7897196261682243, 0.794392523364486)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.score(X_validate, y_validate), model2.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03dc409",
   "metadata": {},
   "source": [
    "Model 2 again performs slightly better on the validate set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc00d2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
